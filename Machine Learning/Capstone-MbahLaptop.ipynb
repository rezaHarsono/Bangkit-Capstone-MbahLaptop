{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Tt6yMnJq5laq"},"outputs":[],"source":["# Import library\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","import tensorflow as tf\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","import plotly.express as px\n","from sklearn.ensemble import RandomForestRegressor\n","import joblib\n","import pickle\n","# name_of_module.__version__"]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/latpopp.csv')\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jt7Tcqp95oVe","executionInfo":{"status":"ok","timestamp":1732899606021,"user_tz":-420,"elapsed":14,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"03363734-776c-4392-ec46-6cae63c7c83b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      brand                                               name  \\\n","0        HP                   Victus 15-fb0157AX Gaming Laptop   \n","1        HP                                15s-fq5007TU Laptop   \n","2      Acer                               One 14 Z8-415 Laptop   \n","3    Lenovo               Yoga Slim 6 14IAP8 82WU0095IN Laptop   \n","4     Apple                    MacBook Air 2020 MGND3HN Laptop   \n","..      ...                                                ...   \n","886    Asus                     TUF A15 FA577RM-HQ032WS Laptop   \n","887    Asus  ROG Zephyrus G14 2023 GA402XV-N2034WS Gaming L...   \n","888    Asus  TUF Gaming F15 2023 FX507VU-LP083WS Gaming Laptop   \n","889    Asus  TUF Gaming A15 2023 FA577XU-LP041WS Gaming Laptop   \n","890     NaN                                                NaN   \n","\n","                         processor   Ram Ram_type  Storage Storage_type  \\\n","0        5th Gen AMD Ryzen 5 5600H   8.0     DDR4    512.0          SSD   \n","1     12th Gen Intel Core i3 1215U   8.0     DDR4    512.0          SSD   \n","2    11th Gen Intel Core i3 1115G4   8.0     DDR4    512.0          SSD   \n","3     12th Gen Intel Core i5 1240P  16.0   LPDDR5    512.0          SSD   \n","4                         Apple M1   8.0     DDR4    256.0          SSD   \n","..                             ...   ...      ...      ...          ...   \n","886  13th Gen ‎Intel Core i3 1315U  16.0      DDR   1024.0          SSD   \n","887      6th Gen AMD Ryzen 7 6800H  32.0     DDR5   1024.0          SSD   \n","888     7th Gen AMD Ryzen 9 7940HS  16.0     DDR4    512.0          SSD   \n","889  13th Gen Intel Core i7 13700H  16.0     DDR4   1024.0          SSD   \n","890     7th Gen AMD Ryzen 9 7940HS   NaN      NaN      NaN          NaN   \n","\n","                                   GPU  display_size  resolution_width  \\\n","0                  AMD Radeon RX 6500M          15.6            1920.0   \n","1        Integrated Intel UHD Graphics          15.6            1920.0   \n","2    Integrated Intel Iris Xe Graphics          14.0            1920.0   \n","3    Integrated Intel Iris Xe Graphics          14.0            2240.0   \n","4         Apple M1 Integrated Graphics          13.3            2560.0   \n","..                                 ...           ...               ...   \n","886            NVIDIA GeForce RTX 3060          15.6            2560.0   \n","887            NVIDIA GeForce RTX 4060          14.0            2560.0   \n","888            NVIDIA GeForce RTX 4050          15.6            1920.0   \n","889            NVIDIA GeForce RTX 4050          15.6            1920.0   \n","890                                NaN           NaN               NaN   \n","\n","     resolution_height             OS       Price  \n","0               1080.0  Windows 11 OS   9381200.0  \n","1               1080.0  Windows 11 OS   7501200.0  \n","2               1080.0  Windows 11 OS   5074120.0  \n","3               1400.0  Windows 11 OS  11229052.0  \n","4               1600.0         Mac OS  13158120.0  \n","..                 ...            ...         ...  \n","886             1440.0  Windows 11 OS  20680000.0  \n","887             1600.0  Windows 11 OS  35718120.0  \n","888             1080.0  Windows 11 OS  24438120.0  \n","889             1080.0  Windows 11 OS  24814120.0  \n","890                NaN            NaN         NaN  \n","\n","[891 rows x 13 columns]\n"]}]},{"cell_type":"code","source":["# Clean outliers\n","def clean_outliers_iqr(data, column):\n","    Q1 = data[column].quantile(0.25)\n","    Q3 = data[column].quantile(0.75)\n","    IQR = Q3 - Q1\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n","\n","# Apply the function to the 'Price' column\n","data = clean_outliers_iqr(data, 'Price')"],"metadata":{"id":"7b5rOXUY5rjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def preprocess_data(data):\n","#     numeric_features = ['Ram', 'Storage', 'display_size', 'resolution_width', 'resolution_height']\n","#     categorical_features = ['processor', 'brand', 'Storage_type', 'GPU', 'OS']\n","\n","#     # Scale numeric data\n","#     scaler = StandardScaler()\n","#     data[numeric_features] = scaler.fit_transform(data[numeric_features])\n","\n","#     # TensorFlow text preprocessing for categorical features\n","#     def tf_categorical_vectorization(data, categorical_features):\n","#         layers = {}\n","#         for col in categorical_features:\n","#             vocab = data[col].unique()\n","#             layer = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)\n","#             layers[col] = layer\n","#         return layers\n","\n","#     cat_layers = tf_categorical_vectorization(data, categorical_features)\n","\n","#     for col, layer in cat_layers.items():\n","#         data[col] = layer(data[col])\n","\n","#     # Splitting features and target\n","#     X = data[numeric_features + categorical_features]\n","#     y = data['Price']\n","#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","#     return X_train, X_test, y_train, y_test\n"],"metadata":{"id":"eMPNFo4O5vSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess data\n","import json\n","import joblib\n","import pickle\n","\n","def preprocess_data(data):\n","  numeric_features = ['Ram', 'Storage', 'display_size', 'resolution_width', 'resolution_height']\n","  categorical_features = ['processor','brand', 'Storage_type', 'GPU', 'OS']\n","\n","\n","  # Numeric Features Preprocess\n","  numeric_preprocessor = StandardScaler()\n","  X_numeric = numeric_preprocessor.fit_transform(data[numeric_features])\n","  X_numeric = pd.DataFrame(X_numeric, columns=numeric_features)\n","\n","  joblib.dump(numeric_preprocessor, 'numeric_preprocessor.pkl')\n","\n","\n","  # Categorical Features Preprocess\n","  categorical_preprocessors = {}\n","  X_categorical_encoded = {}\n","\n","  # Process each categorical feature\n","  for feature in categorical_features:\n","      # TextVectorization layer\n","      vectorizer = tf.keras.layers.TextVectorization(\n","          output_mode='multi_hot',\n","          max_tokens=None,  # Adjust if needed based on your data\n","          standardize='lower_and_strip_punctuation'\n","      )\n","\n","      vectorizer.adapt(data[feature].astype(str))\n","\n","      categorical_preprocessors[feature] = vectorizer\n","\n","      encoded = vectorizer(data[feature].astype(str))\n","      X_categorical_encoded[feature] = encoded.numpy()\n","      print(f\"{feature} vocabulary size: {len(vectorizer.get_vocabulary())}\")\n","\n","\n","  # Combine all features\n","  X_processed = X_numeric.copy()\n","\n","  for feature, encoded_values in X_categorical_encoded.items():\n","      # Get vocabulary size for this feature\n","      vocab_size = len(categorical_preprocessors[feature].get_vocabulary())\n","\n","      encoded_columns = [f\"{feature}_{i}\" for i in range(vocab_size)]\n","\n","\n","      # Convert to DataFrame and concatenate\n","      encoded_df = pd.DataFrame(encoded_values, columns=encoded_columns)\n","      X_processed = pd.concat([X_processed, encoded_df], axis=1)\n","\n","  categorical_vocabularies = {}\n","  for feature, vectorizer in categorical_preprocessors.items():\n","      vocabulary = vectorizer.get_vocabulary()\n","      categorical_vocabularies[feature] = vocabulary\n","      # Save vocabulary to JSON for Android compatibility\n","      with open(f'{feature}_vocabulary.json', 'w') as f:\n","          json.dump(vocabulary, f)\n","\n","  # Create train-test split\n","  y = data['Price']\n","  X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","\n","\n","  return X_train, X_test, y_train, y_test"],"metadata":{"id":"JdSk0kbeCc3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = preprocess_data(data)\n","\n","X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"id":"kuGBmd9h6kxZ","executionInfo":{"status":"ok","timestamp":1732899606022,"user_tz":-420,"elapsed":13,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"89bc1631-c5bf-4e0d-d133-ed58fc02d73e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["processor vocabulary size: 138\n","brand vocabulary size: 30\n","Storage_type vocabulary size: 3\n","GPU vocabulary size: 66\n","OS vocabulary size: 12\n"]},{"output_type":"execute_result","data":{"text/plain":["          Ram   Storage  display_size  resolution_width  resolution_height  \\\n","774 -0.909064 -0.279544      0.518533         -0.151373          -0.330371   \n","526  0.797580 -0.279544      0.518533         -0.151373          -0.330371   \n","655  0.797580 -0.279544      1.067015         -0.151373          -0.330371   \n","581 -0.909064 -0.279544      0.518533         -1.772220          -1.478619   \n","380  0.797580 -0.279544      0.518533         -0.151373          -0.330371   \n","..        ...       ...           ...               ...                ...   \n","71  -0.909064 -0.279544      0.518533         -0.151373          -0.330371   \n","106 -0.909064 -0.279544      0.518533         -0.151373          -0.330371   \n","270  0.797580 -0.279544     -1.236609          5.466003           4.527598   \n","435  0.797580 -0.279544      0.518533         -0.151373          -0.330371   \n","102 -2.189047 -2.358358     -3.869323         -1.772220          -1.478619   \n","\n","     processor_0  processor_1  processor_2  processor_3  processor_4  ...  \\\n","774            0            1            0            0            0  ...   \n","526            0            1            0            0            0  ...   \n","655            0            1            1            1            0  ...   \n","581            0            1            0            0            0  ...   \n","380            0            1            1            1            1  ...   \n","..           ...          ...          ...          ...          ...  ...   \n","71             0            1            0            0            0  ...   \n","106            0            1            1            1            1  ...   \n","270            0            1            1            1            0  ...   \n","435            0            1            1            1            0  ...   \n","102            0            0            1            1            0  ...   \n","\n","     OS_2  OS_3  OS_4  OS_5  OS_6  OS_7  OS_8  OS_9  OS_10  OS_11  \n","774     0     0     0     1     0     0     0     0      0      0  \n","526     1     1     0     0     0     0     0     0      0      0  \n","655     1     1     0     0     0     0     0     0      0      0  \n","581     0     0     0     1     0     0     0     1      0      0  \n","380     1     1     0     0     0     0     0     0      0      0  \n","..    ...   ...   ...   ...   ...   ...   ...   ...    ...    ...  \n","71      1     1     0     0     0     0     0     0      0      0  \n","106     1     1     0     0     0     0     0     0      0      0  \n","270     1     1     0     0     0     0     0     0      0      0  \n","435     1     1     0     0     0     0     0     0      0      0  \n","102     1     0     1     0     0     0     0     0      0      0  \n","\n","[655 rows x 254 columns]"],"text/html":["\n","  <div id=\"df-3cc3d0fb-97cf-420f-944c-109af5163d87\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ram</th>\n","      <th>Storage</th>\n","      <th>display_size</th>\n","      <th>resolution_width</th>\n","      <th>resolution_height</th>\n","      <th>processor_0</th>\n","      <th>processor_1</th>\n","      <th>processor_2</th>\n","      <th>processor_3</th>\n","      <th>processor_4</th>\n","      <th>...</th>\n","      <th>OS_2</th>\n","      <th>OS_3</th>\n","      <th>OS_4</th>\n","      <th>OS_5</th>\n","      <th>OS_6</th>\n","      <th>OS_7</th>\n","      <th>OS_8</th>\n","      <th>OS_9</th>\n","      <th>OS_10</th>\n","      <th>OS_11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>774</th>\n","      <td>-0.909064</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>526</th>\n","      <td>0.797580</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>655</th>\n","      <td>0.797580</td>\n","      <td>-0.279544</td>\n","      <td>1.067015</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>-0.909064</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-1.772220</td>\n","      <td>-1.478619</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>380</th>\n","      <td>0.797580</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>-0.909064</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>-0.909064</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td>0.797580</td>\n","      <td>-0.279544</td>\n","      <td>-1.236609</td>\n","      <td>5.466003</td>\n","      <td>4.527598</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>0.797580</td>\n","      <td>-0.279544</td>\n","      <td>0.518533</td>\n","      <td>-0.151373</td>\n","      <td>-0.330371</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>-2.189047</td>\n","      <td>-2.358358</td>\n","      <td>-3.869323</td>\n","      <td>-1.772220</td>\n","      <td>-1.478619</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>655 rows × 254 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cc3d0fb-97cf-420f-944c-109af5163d87')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3cc3d0fb-97cf-420f-944c-109af5163d87 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3cc3d0fb-97cf-420f-944c-109af5163d87');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c370c71e-3c64-4f7f-8438-23b17ff81307\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c370c71e-3c64-4f7f-8438-23b17ff81307')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c370c71e-3c64-4f7f-8438-23b17ff81307 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7b434f36-842c-4cf4-b9fe-817ead2ec605\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7b434f36-842c-4cf4-b9fe-817ead2ec605 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('X_train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X_train"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Linear Regression\n","model_lr = LinearRegression()\n","model_lr.fit(X_train, y_train)\n","model_lr.score(X_test, y_test)\n","# y_pred = model_lr.predict(X_test)\n","# mae = mean_absolute_error(y_test, y_pred)\n","# print(\"Linear Regression Mean Absolute Error:\", mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzIEL8b953RS","executionInfo":{"status":"ok","timestamp":1732899606022,"user_tz":-420,"elapsed":9,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"a1b69a80-25ca-4386-a5c5-1b1ebbbf6ed8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1.3294388925090822e+21"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Random Forest\n","model_rf = RandomForestRegressor()\n","model_rf.fit(X_train, y_train)\n","model_rf.score(X_test, y_test)\n","# y_pred_rf = model_rf.predict(X_test)\n","# mae_rf = mean_absolute_error(y_test, y_pred_rf)\n","# print(\"Random Forest Mean Absolute Error:\", mae_rf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqJgkYBVgsVw","executionInfo":{"status":"ok","timestamp":1732899607339,"user_tz":-420,"elapsed":1325,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"9aed3d9f-581d-4087-8e9a-64b298082e74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7524784468840988"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# # Temp Quantile Regression\n","# class QuantileRegression(tf.keras.Model):\n","#     def __init__(self, num_quantiles):\n","#         super().__init__()\n","#         self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n","#         self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n","#         self.output_layer = tf.keras.layers.Dense(num_quantiles)\n","\n","#     def call(self, inputs):\n","#         x = self.dense1(inputs)\n","#         x = self.dense2(x)\n","#         return self.output_layer(x)\n","\n","# def quantile_loss(quantile):\n","#     def loss(y_true, y_pred):\n","#         error = y_true - y_pred\n","#         return tf.reduce_mean(tf.maximum(quantile * error, (quantile - 1) * error))\n","#     return loss\n"],"metadata":{"id":"MY-kpZlp54AK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Brr4TArHYuYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model\n","from tensorflow.keras.regularizers import l2\n","\n","def create_model():\n","  model = tf.keras.models.Sequential([])\n","\n","  model.add(tf.keras.layers.Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=l2(0.01)))\n","  model.add(tf.keras.layers.Dense(1, activation='linear'))\n","\n","  return model"],"metadata":{"id":"DtCfq9xwGAQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = create_model()\n","\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='huber', metrics=['mae'])\n","\n","model.summary()"],"metadata":{"id":"BHobpR5G_kfd","colab":{"base_uri":"https://localhost:8080/","height":429},"executionInfo":{"status":"ok","timestamp":1732899607339,"user_tz":-420,"elapsed":8,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"8b5f1247-4fc0-44a0-dc01-71d2d2e60edc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_4\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,320\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m72\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,320</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,417\u001b[0m (75.85 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,417</span> (75.85 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,417\u001b[0m (75.85 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,417</span> (75.85 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Model Train\n","early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=800, batch_size=32, callbacks=[early_stop])\n","# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=800, batch_size=32)"],"metadata":{"id":"1BhQ0YtM_1ic","colab":{"base_uri":"https://localhost:8080/"},"outputId":"847cc06a-eb18-4c7a-8d45-d46b3a7d1f6e","executionInfo":{"status":"ok","timestamp":1732899650471,"user_tz":-420,"elapsed":43138,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 12311953.0000 - mae: 12311952.0000 - val_loss: 12066505.0000 - val_mae: 12066505.0000\n","Epoch 2/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12237143.0000 - mae: 12237143.0000 - val_loss: 12066498.0000 - val_mae: 12066498.0000\n","Epoch 3/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12457755.0000 - mae: 12457756.0000 - val_loss: 12066472.0000 - val_mae: 12066473.0000\n","Epoch 4/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12429850.0000 - mae: 12429850.0000 - val_loss: 12066398.0000 - val_mae: 12066398.0000\n","Epoch 5/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12159593.0000 - mae: 12159593.0000 - val_loss: 12066230.0000 - val_mae: 12066230.0000\n","Epoch 6/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12413547.0000 - mae: 12413547.0000 - val_loss: 12065885.0000 - val_mae: 12065885.0000\n","Epoch 7/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12128255.0000 - mae: 12128255.0000 - val_loss: 12065246.0000 - val_mae: 12065244.0000\n","Epoch 8/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12318380.0000 - mae: 12318377.0000 - val_loss: 12064137.0000 - val_mae: 12064136.0000\n","Epoch 9/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12448792.0000 - mae: 12448790.0000 - val_loss: 12062316.0000 - val_mae: 12062314.0000\n","Epoch 10/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11855507.0000 - mae: 11855504.0000 - val_loss: 12059477.0000 - val_mae: 12059476.0000\n","Epoch 11/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12378910.0000 - mae: 12378907.0000 - val_loss: 12055201.0000 - val_mae: 12055198.0000\n","Epoch 12/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12161143.0000 - mae: 12161140.0000 - val_loss: 12048879.0000 - val_mae: 12048877.0000\n","Epoch 13/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12141933.0000 - mae: 12141930.0000 - val_loss: 12039819.0000 - val_mae: 12039816.0000\n","Epoch 14/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12289448.0000 - mae: 12289443.0000 - val_loss: 12027140.0000 - val_mae: 12027135.0000\n","Epoch 15/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12150864.0000 - mae: 12150858.0000 - val_loss: 12009680.0000 - val_mae: 12009673.0000\n","Epoch 16/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11873605.0000 - mae: 11873598.0000 - val_loss: 11986112.0000 - val_mae: 11986105.0000\n","Epoch 17/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12275263.0000 - mae: 12275257.0000 - val_loss: 11954896.0000 - val_mae: 11954889.0000\n","Epoch 18/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12606707.0000 - mae: 12606698.0000 - val_loss: 11913991.0000 - val_mae: 11913983.0000\n","Epoch 19/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12018162.0000 - mae: 12018155.0000 - val_loss: 11860930.0000 - val_mae: 11860920.0000\n","Epoch 20/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12250880.0000 - mae: 12250872.0000 - val_loss: 11792973.0000 - val_mae: 11792962.0000\n","Epoch 21/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12189891.0000 - mae: 12189878.0000 - val_loss: 11706960.0000 - val_mae: 11706949.0000\n","Epoch 22/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11850808.0000 - mae: 11850797.0000 - val_loss: 11599070.0000 - val_mae: 11599057.0000\n","Epoch 23/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11856563.0000 - mae: 11856550.0000 - val_loss: 11464229.0000 - val_mae: 11464215.0000\n","Epoch 24/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11520413.0000 - mae: 11520401.0000 - val_loss: 11296653.0000 - val_mae: 11296639.0000\n","Epoch 25/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11688746.0000 - mae: 11688731.0000 - val_loss: 11092353.0000 - val_mae: 11092339.0000\n","Epoch 26/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10987535.0000 - mae: 10987519.0000 - val_loss: 10841859.0000 - val_mae: 10841842.0000\n","Epoch 27/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10845373.0000 - mae: 10845356.0000 - val_loss: 10537869.0000 - val_mae: 10537851.0000\n","Epoch 28/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11308931.0000 - mae: 11308913.0000 - val_loss: 10171248.0000 - val_mae: 10171227.0000\n","Epoch 29/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10424940.0000 - mae: 10424919.0000 - val_loss: 9729297.0000 - val_mae: 9729275.0000\n","Epoch 30/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9937670.0000 - mae: 9937649.0000 - val_loss: 9202489.0000 - val_mae: 9202466.0000\n","Epoch 31/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9645985.0000 - mae: 9645962.0000 - val_loss: 8581947.0000 - val_mae: 8581923.0000\n","Epoch 32/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8495952.0000 - mae: 8495928.0000 - val_loss: 7843345.0000 - val_mae: 7843318.5000\n","Epoch 33/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8013723.0000 - mae: 8013697.0000 - val_loss: 6995204.0000 - val_mae: 6995176.0000\n","Epoch 34/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7147669.5000 - mae: 7147642.0000 - val_loss: 6059731.0000 - val_mae: 6059702.5000\n","Epoch 35/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6204420.5000 - mae: 6204391.0000 - val_loss: 5262907.0000 - val_mae: 5262877.0000\n","Epoch 36/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5488712.0000 - mae: 5488682.0000 - val_loss: 4658430.5000 - val_mae: 4658399.0000\n","Epoch 37/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4316210.0000 - mae: 4316178.5000 - val_loss: 4152191.2500 - val_mae: 4152159.2500\n","Epoch 38/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4052815.5000 - mae: 4052782.7500 - val_loss: 3938703.2500 - val_mae: 3938670.5000\n","Epoch 39/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4270794.5000 - mae: 4270761.5000 - val_loss: 3859389.2500 - val_mae: 3859356.5000\n","Epoch 40/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3815001.0000 - mae: 3814967.2500 - val_loss: 3796041.7500 - val_mae: 3796008.2500\n","Epoch 41/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3851078.2500 - mae: 3851045.2500 - val_loss: 3738201.2500 - val_mae: 3738168.2500\n","Epoch 42/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3718346.7500 - mae: 3718313.7500 - val_loss: 3685774.7500 - val_mae: 3685741.2500\n","Epoch 43/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3846655.7500 - mae: 3846622.5000 - val_loss: 3621050.5000 - val_mae: 3621016.5000\n","Epoch 44/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3650974.0000 - mae: 3650940.5000 - val_loss: 3558484.2500 - val_mae: 3558450.2500\n","Epoch 45/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3528868.0000 - mae: 3528834.0000 - val_loss: 3493913.7500 - val_mae: 3493879.7500\n","Epoch 46/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3593388.7500 - mae: 3593354.7500 - val_loss: 3431337.2500 - val_mae: 3431303.7500\n","Epoch 47/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3567445.7500 - mae: 3567411.7500 - val_loss: 3369113.7500 - val_mae: 3369079.7500\n","Epoch 48/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3504724.5000 - mae: 3504690.5000 - val_loss: 3313103.5000 - val_mae: 3313069.2500\n","Epoch 49/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3307399.0000 - mae: 3307364.7500 - val_loss: 3239171.0000 - val_mae: 3239137.0000\n","Epoch 50/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3308671.2500 - mae: 3308637.2500 - val_loss: 3187324.0000 - val_mae: 3187289.5000\n","Epoch 51/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191959.2500 - mae: 3191925.0000 - val_loss: 3120526.0000 - val_mae: 3120491.7500\n","Epoch 52/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3165847.5000 - mae: 3165813.0000 - val_loss: 3054621.7500 - val_mae: 3054587.2500\n","Epoch 53/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3232355.7500 - mae: 3232321.5000 - val_loss: 3005447.5000 - val_mae: 3005412.7500\n","Epoch 54/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2907265.0000 - mae: 2907230.5000 - val_loss: 2964324.0000 - val_mae: 2964289.0000\n","Epoch 55/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2853823.2500 - mae: 2853788.2500 - val_loss: 2876853.0000 - val_mae: 2876817.7500\n","Epoch 56/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2819774.7500 - mae: 2819739.7500 - val_loss: 2826864.0000 - val_mae: 2826829.0000\n","Epoch 57/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2846211.7500 - mae: 2846177.0000 - val_loss: 2781849.2500 - val_mae: 2781813.7500\n","Epoch 58/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2640536.5000 - mae: 2640501.2500 - val_loss: 2716518.7500 - val_mae: 2716483.0000\n","Epoch 59/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2688204.5000 - mae: 2688168.7500 - val_loss: 2665674.2500 - val_mae: 2665638.5000\n","Epoch 60/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2485643.2500 - mae: 2485607.2500 - val_loss: 2616939.0000 - val_mae: 2616903.2500\n","Epoch 61/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2562978.5000 - mae: 2562942.5000 - val_loss: 2568150.2500 - val_mae: 2568114.2500\n","Epoch 62/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2593225.5000 - mae: 2593189.5000 - val_loss: 2525573.0000 - val_mae: 2525536.7500\n","Epoch 63/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2582056.0000 - mae: 2582019.7500 - val_loss: 2487791.5000 - val_mae: 2487755.0000\n","Epoch 64/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2257211.2500 - mae: 2257174.5000 - val_loss: 2441751.5000 - val_mae: 2441714.2500\n","Epoch 65/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2332475.0000 - mae: 2332438.0000 - val_loss: 2407445.0000 - val_mae: 2407407.5000\n","Epoch 66/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2467585.0000 - mae: 2467547.5000 - val_loss: 2375944.2500 - val_mae: 2375906.7500\n","Epoch 67/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2448248.2500 - mae: 2448210.7500 - val_loss: 2335560.5000 - val_mae: 2335523.0000\n","Epoch 68/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2459139.0000 - mae: 2459101.2500 - val_loss: 2307048.0000 - val_mae: 2307010.5000\n","Epoch 69/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2243506.5000 - mae: 2243468.5000 - val_loss: 2275768.2500 - val_mae: 2275730.2500\n","Epoch 70/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2156675.7500 - mae: 2156637.7500 - val_loss: 2245209.7500 - val_mae: 2245171.5000\n","Epoch 71/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2427366.0000 - mae: 2427327.5000 - val_loss: 2213908.0000 - val_mae: 2213869.5000\n","Epoch 72/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2345060.2500 - mae: 2345021.7500 - val_loss: 2196986.5000 - val_mae: 2196948.2500\n","Epoch 73/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2216834.0000 - mae: 2216795.2500 - val_loss: 2169221.5000 - val_mae: 2169182.5000\n","Epoch 74/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2034234.6250 - mae: 2034195.6250 - val_loss: 2160020.0000 - val_mae: 2159981.0000\n","Epoch 75/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2228803.0000 - mae: 2228763.7500 - val_loss: 2129423.2500 - val_mae: 2129383.7500\n","Epoch 76/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1948906.0000 - mae: 1948866.3750 - val_loss: 2117297.7500 - val_mae: 2117258.2500\n","Epoch 77/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2234030.0000 - mae: 2233990.5000 - val_loss: 2091712.0000 - val_mae: 2091671.7500\n","Epoch 78/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2106194.7500 - mae: 2106154.7500 - val_loss: 2071117.8750 - val_mae: 2071077.8750\n","Epoch 79/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2134861.2500 - mae: 2134821.0000 - val_loss: 2061110.8750 - val_mae: 2061070.2500\n","Epoch 80/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2121708.5000 - mae: 2121668.0000 - val_loss: 2043366.0000 - val_mae: 2043325.2500\n","Epoch 81/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1965449.2500 - mae: 1965408.6250 - val_loss: 2026642.5000 - val_mae: 2026601.7500\n","Epoch 82/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2146379.0000 - mae: 2146338.5000 - val_loss: 2009174.0000 - val_mae: 2009133.1250\n","Epoch 83/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2106672.2500 - mae: 2106631.0000 - val_loss: 1995959.6250 - val_mae: 1995918.2500\n","Epoch 84/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1988275.5000 - mae: 1988234.2500 - val_loss: 1979809.1250 - val_mae: 1979767.7500\n","Epoch 85/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2076818.6250 - mae: 2076777.2500 - val_loss: 1970774.6250 - val_mae: 1970732.8750\n","Epoch 86/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1972210.6250 - mae: 1972168.8750 - val_loss: 1966330.8750 - val_mae: 1966289.0000\n","Epoch 87/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1985828.0000 - mae: 1985785.7500 - val_loss: 1942663.2500 - val_mae: 1942621.2500\n","Epoch 88/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1906575.3750 - mae: 1906533.1250 - val_loss: 1926626.8750 - val_mae: 1926584.6250\n","Epoch 89/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1889871.7500 - mae: 1889829.1250 - val_loss: 1912050.7500 - val_mae: 1912007.7500\n","Epoch 90/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1997471.0000 - mae: 1997428.0000 - val_loss: 1898746.8750 - val_mae: 1898704.0000\n","Epoch 91/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1964284.3750 - mae: 1964241.2500 - val_loss: 1887886.8750 - val_mae: 1887843.7500\n","Epoch 92/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1788542.5000 - mae: 1788499.0000 - val_loss: 1887696.2500 - val_mae: 1887652.5000\n","Epoch 93/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1863610.7500 - mae: 1863566.8750 - val_loss: 1862252.2500 - val_mae: 1862208.7500\n","Epoch 94/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1875790.0000 - mae: 1875746.1250 - val_loss: 1849860.6250 - val_mae: 1849816.6250\n","Epoch 95/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1927909.5000 - mae: 1927865.2500 - val_loss: 1875961.1250 - val_mae: 1875916.8750\n","Epoch 96/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1836772.6250 - mae: 1836728.0000 - val_loss: 1830514.0000 - val_mae: 1830469.5000\n","Epoch 97/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1988047.6250 - mae: 1988002.8750 - val_loss: 1827358.0000 - val_mae: 1827313.0000\n","Epoch 98/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1945162.6250 - mae: 1945117.6250 - val_loss: 1810013.6250 - val_mae: 1809968.6250\n","Epoch 99/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1806896.5000 - mae: 1806851.2500 - val_loss: 1798400.6250 - val_mae: 1798355.1250\n","Epoch 100/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1709733.5000 - mae: 1709688.0000 - val_loss: 1792721.7500 - val_mae: 1792676.1250\n","Epoch 101/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1741671.8750 - mae: 1741626.1250 - val_loss: 1779840.2500 - val_mae: 1779794.3750\n","Epoch 102/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1773498.5000 - mae: 1773452.5000 - val_loss: 1777497.5000 - val_mae: 1777451.1250\n","Epoch 103/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1745585.1250 - mae: 1745538.8750 - val_loss: 1761469.5000 - val_mae: 1761423.0000\n","Epoch 104/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1834324.6250 - mae: 1834278.1250 - val_loss: 1765184.0000 - val_mae: 1765137.1250\n","Epoch 105/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1718215.7500 - mae: 1718169.0000 - val_loss: 1748986.0000 - val_mae: 1748938.7500\n","Epoch 106/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1765363.1250 - mae: 1765316.0000 - val_loss: 1741190.0000 - val_mae: 1741142.6250\n","Epoch 107/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1615364.5000 - mae: 1615317.1250 - val_loss: 1738997.1250 - val_mae: 1738949.5000\n","Epoch 108/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1707496.6250 - mae: 1707448.8750 - val_loss: 1728869.5000 - val_mae: 1728821.6250\n","Epoch 109/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1656009.0000 - mae: 1655961.2500 - val_loss: 1721719.7500 - val_mae: 1721671.7500\n","Epoch 110/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1683419.0000 - mae: 1683370.8750 - val_loss: 1699058.7500 - val_mae: 1699010.7500\n","Epoch 111/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1821818.0000 - mae: 1821769.6250 - val_loss: 1693507.3750 - val_mae: 1693458.8750\n","Epoch 112/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1606872.2500 - mae: 1606823.7500 - val_loss: 1685808.6250 - val_mae: 1685760.0000\n","Epoch 113/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1636931.5000 - mae: 1636882.6250 - val_loss: 1687335.6250 - val_mae: 1687286.6250\n","Epoch 114/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1494858.2500 - mae: 1494809.2500 - val_loss: 1671308.2500 - val_mae: 1671258.8750\n","Epoch 115/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1575183.6250 - mae: 1575134.3750 - val_loss: 1662262.2500 - val_mae: 1662212.8750\n","Epoch 116/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1656738.0000 - mae: 1656688.3750 - val_loss: 1656073.5000 - val_mae: 1656023.7500\n","Epoch 117/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1570803.7500 - mae: 1570754.0000 - val_loss: 1648534.0000 - val_mae: 1648483.8750\n","Epoch 118/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1564632.8750 - mae: 1564582.7500 - val_loss: 1646273.1250 - val_mae: 1646223.0000\n","Epoch 119/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1636920.7500 - mae: 1636870.5000 - val_loss: 1638563.8750 - val_mae: 1638513.3750\n","Epoch 120/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1629792.6250 - mae: 1629742.2500 - val_loss: 1635330.7500 - val_mae: 1635280.2500\n","Epoch 121/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1413427.5000 - mae: 1413376.8750 - val_loss: 1625160.2500 - val_mae: 1625109.5000\n","Epoch 122/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1593835.6250 - mae: 1593784.5000 - val_loss: 1622247.6250 - val_mae: 1622196.5000\n","Epoch 123/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1749203.7500 - mae: 1749152.3750 - val_loss: 1615488.5000 - val_mae: 1615437.1250\n","Epoch 124/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1480723.0000 - mae: 1480671.6250 - val_loss: 1611248.6250 - val_mae: 1611197.1250\n","Epoch 125/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1521711.8750 - mae: 1521660.1250 - val_loss: 1605659.5000 - val_mae: 1605607.7500\n","Epoch 126/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1471087.7500 - mae: 1471035.8750 - val_loss: 1597779.8750 - val_mae: 1597727.8750\n","Epoch 127/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1641321.5000 - mae: 1641269.3750 - val_loss: 1590364.1250 - val_mae: 1590311.7500\n","Epoch 128/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1587574.7500 - mae: 1587522.1250 - val_loss: 1585889.7500 - val_mae: 1585837.2500\n","Epoch 129/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1594572.1250 - mae: 1594519.5000 - val_loss: 1583537.3750 - val_mae: 1583484.3750\n","Epoch 130/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1476350.0000 - mae: 1476297.1250 - val_loss: 1574333.2500 - val_mae: 1574280.1250\n","Epoch 131/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1469470.0000 - mae: 1469416.8750 - val_loss: 1574058.5000 - val_mae: 1574005.2500\n","Epoch 132/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1453632.0000 - mae: 1453578.6250 - val_loss: 1568851.3750 - val_mae: 1568797.8750\n","Epoch 133/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1525769.7500 - mae: 1525716.1250 - val_loss: 1561057.8750 - val_mae: 1561004.2500\n","Epoch 134/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1604184.2500 - mae: 1604130.2500 - val_loss: 1554735.5000 - val_mae: 1554681.5000\n","Epoch 135/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1503854.8750 - mae: 1503800.8750 - val_loss: 1555683.2500 - val_mae: 1555629.1250\n","Epoch 136/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1399126.2500 - mae: 1399071.8750 - val_loss: 1553335.8750 - val_mae: 1553281.3750\n","Epoch 137/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1570523.8750 - mae: 1570469.2500 - val_loss: 1548461.7500 - val_mae: 1548406.8750\n","Epoch 138/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1554691.0000 - mae: 1554636.2500 - val_loss: 1555764.0000 - val_mae: 1555709.2500\n","Epoch 139/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1453665.3750 - mae: 1453610.6250 - val_loss: 1546462.1250 - val_mae: 1546406.8750\n","Epoch 140/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1397662.3750 - mae: 1397607.2500 - val_loss: 1538553.1250 - val_mae: 1538498.0000\n","Epoch 141/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1355321.1250 - mae: 1355265.7500 - val_loss: 1538387.7500 - val_mae: 1538332.2500\n","Epoch 142/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1402631.0000 - mae: 1402575.5000 - val_loss: 1544306.8750 - val_mae: 1544251.2500\n","Epoch 143/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1362832.2500 - mae: 1362776.5000 - val_loss: 1534069.2500 - val_mae: 1534013.3750\n","Epoch 144/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1329751.7500 - mae: 1329695.7500 - val_loss: 1530960.1250 - val_mae: 1530904.1250\n","Epoch 145/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1446547.7500 - mae: 1446491.7500 - val_loss: 1533842.1250 - val_mae: 1533785.7500\n","Epoch 146/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1333112.5000 - mae: 1333056.2500 - val_loss: 1530841.0000 - val_mae: 1530784.5000\n","Epoch 147/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1409750.1250 - mae: 1409693.6250 - val_loss: 1528038.5000 - val_mae: 1527982.1250\n","Epoch 148/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1560374.2500 - mae: 1560317.8750 - val_loss: 1525567.1250 - val_mae: 1525510.3750\n","Epoch 149/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1453746.7500 - mae: 1453690.0000 - val_loss: 1537666.2500 - val_mae: 1537609.5000\n","Epoch 150/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1432566.1250 - mae: 1432509.1250 - val_loss: 1522279.7500 - val_mae: 1522222.6250\n","Epoch 151/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1325679.0000 - mae: 1325621.8750 - val_loss: 1520966.7500 - val_mae: 1520909.5000\n","Epoch 152/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1512229.3750 - mae: 1512172.1250 - val_loss: 1519092.6250 - val_mae: 1519035.2500\n","Epoch 153/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1543583.7500 - mae: 1543526.1250 - val_loss: 1516506.5000 - val_mae: 1516448.6250\n","Epoch 154/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1369284.3750 - mae: 1369226.6250 - val_loss: 1517772.7500 - val_mae: 1517714.8750\n","Epoch 155/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1439527.7500 - mae: 1439469.6250 - val_loss: 1524689.5000 - val_mae: 1524631.2500\n","Epoch 156/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1384744.6250 - mae: 1384686.3750 - val_loss: 1519469.6250 - val_mae: 1519411.3750\n","Epoch 157/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1391648.7500 - mae: 1391590.5000 - val_loss: 1512568.6250 - val_mae: 1512510.1250\n","Epoch 158/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1306198.2500 - mae: 1306139.8750 - val_loss: 1512480.6250 - val_mae: 1512421.8750\n","Epoch 159/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1448736.2500 - mae: 1448677.3750 - val_loss: 1516460.8750 - val_mae: 1516401.8750\n","Epoch 160/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1369825.7500 - mae: 1369766.7500 - val_loss: 1511948.5000 - val_mae: 1511889.3750\n","Epoch 161/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1377523.0000 - mae: 1377463.8750 - val_loss: 1501704.2500 - val_mae: 1501645.1250\n","Epoch 162/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1462084.8750 - mae: 1462025.7500 - val_loss: 1502884.7500 - val_mae: 1502825.5000\n","Epoch 163/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1368273.7500 - mae: 1368214.2500 - val_loss: 1500546.8750 - val_mae: 1500487.3750\n","Epoch 164/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1392738.0000 - mae: 1392678.6250 - val_loss: 1503615.6250 - val_mae: 1503555.7500\n","Epoch 165/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1353290.1250 - mae: 1353230.2500 - val_loss: 1504795.2500 - val_mae: 1504735.5000\n","Epoch 166/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1438435.5000 - mae: 1438375.6250 - val_loss: 1504221.2500 - val_mae: 1504161.3750\n","Epoch 167/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1351289.0000 - mae: 1351229.0000 - val_loss: 1504860.2500 - val_mae: 1504800.2500\n","Epoch 168/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1350033.2500 - mae: 1349973.1250 - val_loss: 1496334.7500 - val_mae: 1496274.2500\n","Epoch 169/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1298205.8750 - mae: 1298145.5000 - val_loss: 1492229.5000 - val_mae: 1492169.0000\n","Epoch 170/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1449343.7500 - mae: 1449283.0000 - val_loss: 1491444.5000 - val_mae: 1491383.7500\n","Epoch 171/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1434097.1250 - mae: 1434036.3750 - val_loss: 1487066.8750 - val_mae: 1487006.0000\n","Epoch 172/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1350366.3750 - mae: 1350305.5000 - val_loss: 1486567.0000 - val_mae: 1486506.0000\n","Epoch 173/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1480235.5000 - mae: 1480174.2500 - val_loss: 1485454.8750 - val_mae: 1485393.6250\n","Epoch 174/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1362736.7500 - mae: 1362675.5000 - val_loss: 1486944.2500 - val_mae: 1486882.6250\n","Epoch 175/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1354822.2500 - mae: 1354761.0000 - val_loss: 1483190.5000 - val_mae: 1483129.0000\n","Epoch 176/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1326009.6250 - mae: 1325948.0000 - val_loss: 1496133.7500 - val_mae: 1496071.7500\n","Epoch 177/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1312747.6250 - mae: 1312685.7500 - val_loss: 1481428.6250 - val_mae: 1481366.8750\n","Epoch 178/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1380727.0000 - mae: 1380665.0000 - val_loss: 1479219.7500 - val_mae: 1479157.6250\n","Epoch 179/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1413960.1250 - mae: 1413897.7500 - val_loss: 1472859.3750 - val_mae: 1472797.1250\n","Epoch 180/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1373773.8750 - mae: 1373711.6250 - val_loss: 1472572.0000 - val_mae: 1472509.5000\n","Epoch 181/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1412889.1250 - mae: 1412826.3750 - val_loss: 1476279.0000 - val_mae: 1476216.3750\n","Epoch 182/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1324040.1250 - mae: 1323977.3750 - val_loss: 1485009.3750 - val_mae: 1484946.5000\n","Epoch 183/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1388769.7500 - mae: 1388706.8750 - val_loss: 1465676.1250 - val_mae: 1465613.1250\n","Epoch 184/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1306037.5000 - mae: 1305974.5000 - val_loss: 1475655.0000 - val_mae: 1475592.0000\n","Epoch 185/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1398989.8750 - mae: 1398926.7500 - val_loss: 1462036.2500 - val_mae: 1461973.0000\n","Epoch 186/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1334329.0000 - mae: 1334265.7500 - val_loss: 1479800.2500 - val_mae: 1479736.8750\n","Epoch 187/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1263560.2500 - mae: 1263496.8750 - val_loss: 1458833.5000 - val_mae: 1458770.0000\n","Epoch 188/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1342792.7500 - mae: 1342729.1250 - val_loss: 1456196.1250 - val_mae: 1456132.5000\n","Epoch 189/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1303051.2500 - mae: 1302987.3750 - val_loss: 1455131.0000 - val_mae: 1455067.2500\n","Epoch 190/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1256080.0000 - mae: 1256016.0000 - val_loss: 1477009.0000 - val_mae: 1476944.6250\n","Epoch 191/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1253799.6250 - mae: 1253735.3750 - val_loss: 1454933.2500 - val_mae: 1454869.1250\n","Epoch 192/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1343684.6250 - mae: 1343620.5000 - val_loss: 1454342.6250 - val_mae: 1454278.2500\n","Epoch 193/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1358634.6250 - mae: 1358570.3750 - val_loss: 1451390.0000 - val_mae: 1451325.5000\n","Epoch 194/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1275525.6250 - mae: 1275461.0000 - val_loss: 1457250.6250 - val_mae: 1457186.1250\n","Epoch 195/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1434087.1250 - mae: 1434022.5000 - val_loss: 1446610.0000 - val_mae: 1446545.1250\n","Epoch 196/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1318479.3750 - mae: 1318414.5000 - val_loss: 1444054.7500 - val_mae: 1443989.6250\n","Epoch 197/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1239709.1250 - mae: 1239644.0000 - val_loss: 1445703.2500 - val_mae: 1445638.0000\n","Epoch 198/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1312811.7500 - mae: 1312746.5000 - val_loss: 1446677.7500 - val_mae: 1446612.6250\n","Epoch 199/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1345570.8750 - mae: 1345505.6250 - val_loss: 1441800.0000 - val_mae: 1441734.5000\n","Epoch 200/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1267576.5000 - mae: 1267510.8750 - val_loss: 1440752.6250 - val_mae: 1440686.8750\n","Epoch 201/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1403465.8750 - mae: 1403400.0000 - val_loss: 1441860.5000 - val_mae: 1441794.5000\n","Epoch 202/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1215139.5000 - mae: 1215073.3750 - val_loss: 1443218.5000 - val_mae: 1443152.3750\n","Epoch 203/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1336096.1250 - mae: 1336030.0000 - val_loss: 1440500.8750 - val_mae: 1440434.6250\n","Epoch 204/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1265632.0000 - mae: 1265565.7500 - val_loss: 1439229.0000 - val_mae: 1439162.5000\n","Epoch 205/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1253026.1250 - mae: 1252959.5000 - val_loss: 1433531.0000 - val_mae: 1433464.6250\n","Epoch 206/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237756.3750 - mae: 1237689.7500 - val_loss: 1430918.5000 - val_mae: 1430851.7500\n","Epoch 207/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1172247.2500 - mae: 1172180.6250 - val_loss: 1429654.7500 - val_mae: 1429587.7500\n","Epoch 208/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1297308.1250 - mae: 1297241.2500 - val_loss: 1434509.5000 - val_mae: 1434442.2500\n","Epoch 209/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1364569.7500 - mae: 1364502.6250 - val_loss: 1430444.1250 - val_mae: 1430376.8750\n","Epoch 210/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1229854.2500 - mae: 1229786.8750 - val_loss: 1427301.2500 - val_mae: 1427233.8750\n","Epoch 211/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1214082.2500 - mae: 1214014.6250 - val_loss: 1444213.0000 - val_mae: 1444145.3750\n","Epoch 212/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1381012.1250 - mae: 1380944.3750 - val_loss: 1426137.7500 - val_mae: 1426070.0000\n","Epoch 213/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1282277.6250 - mae: 1282209.8750 - val_loss: 1448823.3750 - val_mae: 1448755.3750\n","Epoch 214/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1265738.2500 - mae: 1265670.2500 - val_loss: 1422173.6250 - val_mae: 1422105.6250\n","Epoch 215/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1168270.1250 - mae: 1168202.0000 - val_loss: 1426732.7500 - val_mae: 1426664.5000\n","Epoch 216/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1213165.6250 - mae: 1213097.2500 - val_loss: 1439924.1250 - val_mae: 1439855.6250\n","Epoch 217/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1282314.0000 - mae: 1282245.6250 - val_loss: 1411586.2500 - val_mae: 1411517.7500\n","Epoch 218/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1253712.5000 - mae: 1253643.8750 - val_loss: 1411778.1250 - val_mae: 1411709.5000\n","Epoch 219/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1275530.5000 - mae: 1275461.7500 - val_loss: 1412005.1250 - val_mae: 1411936.5000\n","Epoch 220/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1260589.2500 - mae: 1260520.2500 - val_loss: 1411741.5000 - val_mae: 1411672.3750\n","Epoch 221/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1165833.3750 - mae: 1165764.2500 - val_loss: 1407854.5000 - val_mae: 1407785.2500\n","Epoch 222/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1242420.3750 - mae: 1242351.0000 - val_loss: 1404098.0000 - val_mae: 1404028.7500\n","Epoch 223/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1308419.7500 - mae: 1308350.2500 - val_loss: 1404659.1250 - val_mae: 1404589.6250\n","Epoch 224/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1290288.8750 - mae: 1290219.3750 - val_loss: 1418703.7500 - val_mae: 1418634.0000\n","Epoch 225/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1309895.6250 - mae: 1309825.8750 - val_loss: 1408515.7500 - val_mae: 1408446.0000\n","Epoch 226/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1272391.7500 - mae: 1272321.8750 - val_loss: 1398989.2500 - val_mae: 1398919.2500\n","Epoch 227/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1269849.0000 - mae: 1269778.8750 - val_loss: 1400696.2500 - val_mae: 1400626.0000\n","Epoch 228/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1225342.0000 - mae: 1225271.7500 - val_loss: 1411376.6250 - val_mae: 1411306.2500\n","Epoch 229/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1207255.7500 - mae: 1207185.5000 - val_loss: 1401015.0000 - val_mae: 1400944.6250\n","Epoch 230/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1131031.1250 - mae: 1130960.6250 - val_loss: 1417781.2500 - val_mae: 1417710.6250\n","Epoch 231/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1322921.7500 - mae: 1322851.1250 - val_loss: 1393818.5000 - val_mae: 1393747.6250\n","Epoch 232/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1252248.6250 - mae: 1252177.8750 - val_loss: 1395946.2500 - val_mae: 1395875.3750\n","Epoch 233/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1192320.3750 - mae: 1192249.5000 - val_loss: 1398300.5000 - val_mae: 1398229.2500\n","Epoch 234/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1278609.2500 - mae: 1278538.2500 - val_loss: 1392211.1250 - val_mae: 1392140.0000\n","Epoch 235/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1269293.7500 - mae: 1269222.5000 - val_loss: 1397215.3750 - val_mae: 1397144.1250\n","Epoch 236/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1145150.1250 - mae: 1145078.7500 - val_loss: 1403789.1250 - val_mae: 1403717.6250\n","Epoch 237/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1284847.6250 - mae: 1284776.2500 - val_loss: 1387584.0000 - val_mae: 1387512.3750\n","Epoch 238/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1257527.8750 - mae: 1257456.3750 - val_loss: 1427195.7500 - val_mae: 1427123.8750\n","Epoch 239/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1159163.3750 - mae: 1159091.7500 - val_loss: 1393851.3750 - val_mae: 1393779.5000\n","Epoch 240/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1238497.2500 - mae: 1238425.5000 - val_loss: 1386899.5000 - val_mae: 1386827.6250\n","Epoch 241/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1174522.6250 - mae: 1174450.5000 - val_loss: 1399598.5000 - val_mae: 1399526.3750\n","Epoch 242/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1224374.3750 - mae: 1224302.2500 - val_loss: 1393216.6250 - val_mae: 1393144.2500\n","Epoch 243/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1229448.2500 - mae: 1229376.1250 - val_loss: 1382903.5000 - val_mae: 1382831.3750\n","Epoch 244/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1183550.2500 - mae: 1183477.8750 - val_loss: 1381711.6250 - val_mae: 1381639.2500\n","Epoch 245/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1168955.0000 - mae: 1168882.6250 - val_loss: 1400713.5000 - val_mae: 1400641.0000\n","Epoch 246/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1181674.1250 - mae: 1181601.5000 - val_loss: 1405463.7500 - val_mae: 1405391.1250\n","Epoch 247/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1208206.6250 - mae: 1208133.7500 - val_loss: 1379147.1250 - val_mae: 1379074.5000\n","Epoch 248/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1328745.8750 - mae: 1328673.0000 - val_loss: 1412983.0000 - val_mae: 1412910.0000\n","Epoch 249/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1221811.8750 - mae: 1221738.8750 - val_loss: 1378466.5000 - val_mae: 1378393.5000\n","Epoch 250/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1172497.0000 - mae: 1172423.8750 - val_loss: 1385849.3750 - val_mae: 1385776.2500\n","Epoch 251/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1228062.5000 - mae: 1227989.2500 - val_loss: 1379557.1250 - val_mae: 1379484.1250\n","Epoch 252/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1206296.7500 - mae: 1206223.5000 - val_loss: 1412163.1250 - val_mae: 1412089.6250\n","Epoch 253/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1229985.0000 - mae: 1229911.5000 - val_loss: 1380129.8750 - val_mae: 1380056.2500\n","Epoch 254/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1190020.6250 - mae: 1189947.0000 - val_loss: 1373564.2500 - val_mae: 1373490.5000\n","Epoch 255/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1227447.0000 - mae: 1227373.2500 - val_loss: 1379149.8750 - val_mae: 1379076.0000\n","Epoch 256/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1136687.7500 - mae: 1136614.0000 - val_loss: 1376751.7500 - val_mae: 1376677.8750\n","Epoch 257/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1197695.3750 - mae: 1197621.3750 - val_loss: 1382827.6250 - val_mae: 1382753.5000\n","Epoch 258/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1179163.8750 - mae: 1179089.8750 - val_loss: 1373625.7500 - val_mae: 1373551.6250\n","Epoch 259/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1088995.8750 - mae: 1088921.6250 - val_loss: 1370530.5000 - val_mae: 1370456.6250\n","Epoch 260/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1089659.2500 - mae: 1089585.0000 - val_loss: 1379275.1250 - val_mae: 1379200.6250\n","Epoch 261/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1199419.8750 - mae: 1199345.3750 - val_loss: 1374117.5000 - val_mae: 1374043.1250\n","Epoch 262/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1290023.6250 - mae: 1289949.0000 - val_loss: 1367209.7500 - val_mae: 1367135.2500\n","Epoch 263/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1163711.5000 - mae: 1163636.8750 - val_loss: 1367048.2500 - val_mae: 1366973.5000\n","Epoch 264/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1129701.0000 - mae: 1129626.1250 - val_loss: 1372064.3750 - val_mae: 1371989.6250\n","Epoch 265/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1359834.7500 - mae: 1359759.8750 - val_loss: 1372664.6250 - val_mae: 1372589.6250\n","Epoch 266/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1201343.7500 - mae: 1201268.7500 - val_loss: 1371360.3750 - val_mae: 1371285.5000\n","Epoch 267/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1309153.1250 - mae: 1309078.0000 - val_loss: 1371578.7500 - val_mae: 1371503.7500\n","Epoch 268/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1145670.6250 - mae: 1145595.3750 - val_loss: 1368420.7500 - val_mae: 1368345.5000\n","Epoch 269/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1227849.2500 - mae: 1227774.0000 - val_loss: 1372994.1250 - val_mae: 1372918.8750\n","Epoch 270/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1081607.2500 - mae: 1081531.8750 - val_loss: 1370216.2500 - val_mae: 1370140.6250\n","Epoch 271/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1156507.3750 - mae: 1156431.7500 - val_loss: 1368939.0000 - val_mae: 1368863.1250\n","Epoch 272/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286747.8750 - mae: 1286672.2500 - val_loss: 1368788.6250 - val_mae: 1368713.0000\n","Epoch 273/800\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1132189.2500 - mae: 1132113.5000 - val_loss: 1383486.6250 - val_mae: 1383410.6250\n"]}]},{"cell_type":"code","source":["model.save('mbahlaptop_V0.1.h5')"],"metadata":{"id":"I1yi8v4TtSJj","executionInfo":{"status":"ok","timestamp":1732899650474,"user_tz":-420,"elapsed":92,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"e419d0e6-6e6c-410f-a255-f3880bb6057d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","with open('mbahlaptop.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"OEG7b0tJuZOM","executionInfo":{"status":"ok","timestamp":1732899650475,"user_tz":-420,"elapsed":35,"user":{"displayName":"Juan Graciano","userId":"02761195619758998119"}},"outputId":"1df49767-44b5-4a45-f788-2abc594ea1cc","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmpbepj3d2x'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 254), dtype=tf.float32, name='keras_tensor_72')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  134279335676912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279335686240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279491161600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279491169344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279501239696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279490976432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279517832288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279491676368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279492476720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279490524032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279525452432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279490524912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279490532480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134279492366784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]}]}]}